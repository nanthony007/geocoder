{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Geocoding Analysis Homepage The GitHub homepage can be found here Description This project is designed to take the open-source dataset for the Chicago Medical Case Examiner's Notes ( here ) and combine it with the openly available Chicago Land Use datasets ( here ) to analyze trends by Land Use area and geographic regions. Installation Getting this project up and running locally is a multi-step process. First, you can clone the git repository onto your local machine and change into that directory. git clone https://github.com/UK-IPOP/geocoding.git cd geocoding Then you can install the projects main dependencies: poetry install --no-dev or install all dependencies (including development) using poetry install . Then activate the poetry created virtual environment by running poetry shell . Now you're code environment is ready. Post-Installation Setup However, before you run the pipeline, you need to do some preparation. Firstly you need to download the shapefiles and extract the folder from the Land Use Website . Put the extracted folder into the resources folder inside the geocoding project. You then need to go to the Chicago ME Records website and download their data in *.csv format and place it into the data directory of the geocoding project. *These records will be geocoded which can take hours so it is recommended to pre-filter your data using the Cook County Open Data explorer. Methodology In order to perform this analysis, we conducted all of the above steps regarding project setup. We extracted all of the ME Records on [ DATE ]. We then ran the pipeline and used the resulting data-file for analysis in [PAPER] . To see an example of potential analysis that could result from this, see our Tutorial Notebook . Pipeline Explanation The pipeline has multiple stages that need to run in succession. Take the raw Land Use files and apply the Data Dictionary (extracted from this PDF ) to each Land Use polygon. Geocode the pharmacies provided by Cook County. Geocode Case Archive records. Calculate the distance to the closest pharmacy from each Case Archive record. Spatially join the Land Use shapes to the Case Archive records giving each record a corresponding Land Use category. The following image may more clearly explain the data flow: Pipeline Flowchart Pipeline Usage Running the pipeline is simple once you have everything setup. Inside the home directory of the geocoding project simply run: make pipeline This can take up to 12 hours depending on the system you are running and the number of ME records you are geocoding. Future efforts may be made to speed this process up using asynchronous geocoding. If you wish to remove any steps from the pipeline those lines can simply be removed from the Makefile Support For questions on implementation or issues you can either make a GitHub Issue or contact @nanthony007 License This project is GNU v3 Licensed which means that work you perform utilizing this project must attribute to this project (the source), you must disclose any source-changes you make, and your resulting work must also be GPLv3 Licensed. Citation If you use this work, please cite: @@@ citation","title":"Home"},{"location":"#geocoding-analysis","text":"","title":"Geocoding Analysis"},{"location":"#homepage","text":"The GitHub homepage can be found here","title":"Homepage"},{"location":"#description","text":"This project is designed to take the open-source dataset for the Chicago Medical Case Examiner's Notes ( here ) and combine it with the openly available Chicago Land Use datasets ( here ) to analyze trends by Land Use area and geographic regions.","title":"Description"},{"location":"#installation","text":"Getting this project up and running locally is a multi-step process. First, you can clone the git repository onto your local machine and change into that directory. git clone https://github.com/UK-IPOP/geocoding.git cd geocoding Then you can install the projects main dependencies: poetry install --no-dev or install all dependencies (including development) using poetry install . Then activate the poetry created virtual environment by running poetry shell . Now you're code environment is ready.","title":"Installation"},{"location":"#post-installation-setup","text":"However, before you run the pipeline, you need to do some preparation. Firstly you need to download the shapefiles and extract the folder from the Land Use Website . Put the extracted folder into the resources folder inside the geocoding project. You then need to go to the Chicago ME Records website and download their data in *.csv format and place it into the data directory of the geocoding project. *These records will be geocoded which can take hours so it is recommended to pre-filter your data using the Cook County Open Data explorer.","title":"Post-Installation Setup"},{"location":"#methodology","text":"In order to perform this analysis, we conducted all of the above steps regarding project setup. We extracted all of the ME Records on [ DATE ]. We then ran the pipeline and used the resulting data-file for analysis in [PAPER] . To see an example of potential analysis that could result from this, see our Tutorial Notebook .","title":"Methodology"},{"location":"#pipeline-explanation","text":"The pipeline has multiple stages that need to run in succession. Take the raw Land Use files and apply the Data Dictionary (extracted from this PDF ) to each Land Use polygon. Geocode the pharmacies provided by Cook County. Geocode Case Archive records. Calculate the distance to the closest pharmacy from each Case Archive record. Spatially join the Land Use shapes to the Case Archive records giving each record a corresponding Land Use category. The following image may more clearly explain the data flow:","title":"Pipeline Explanation"},{"location":"#pipeline-flowchart","text":"","title":"Pipeline Flowchart"},{"location":"#pipeline-usage","text":"Running the pipeline is simple once you have everything setup. Inside the home directory of the geocoding project simply run: make pipeline This can take up to 12 hours depending on the system you are running and the number of ME records you are geocoding. Future efforts may be made to speed this process up using asynchronous geocoding. If you wish to remove any steps from the pipeline those lines can simply be removed from the Makefile","title":"Pipeline Usage"},{"location":"#support","text":"For questions on implementation or issues you can either make a GitHub Issue or contact @nanthony007","title":"Support"},{"location":"#license","text":"This project is GNU v3 Licensed which means that work you perform utilizing this project must attribute to this project (the source), you must disclose any source-changes you make, and your resulting work must also be GPLv3 Licensed.","title":"License"},{"location":"#citation","text":"If you use this work, please cite: @@@ citation","title":"Citation"},{"location":"api-reference/case-archive-utils/","text":"Case Archive Utils calculate_distance ( df ) Calculates distance from original lat/long to geocoded lat/long. Parameters: Name Type Description Default df DataFrame original df required Returns: Type Description DataFrame pd.DataFrame: dataframe with distance column Source code in geocoding/case_archive_utils.py def calculate_distance ( df : pd . DataFrame ) -> pd . DataFrame : \"\"\"Calculates distance from original lat/long to geocoded lat/long. Args: df (pd.DataFrame): original df Returns: pd.DataFrame: dataframe with distance column \"\"\" def calc_distance ( row ) -> Union [ None , float ]: if ( pd . isna ( row . latitude ) or pd . isna ( row . longitude ) or pd . isna ( row . coded_lat ) or pd . isna ( row . coded_long ) ): return None # distance in miles d = distance . distance ( ( row . latitude , row . longitude ), ( row . coded_lat , row . coded_long ) ) . mi return d df [ \"distance\" ] = df . apply ( lambda row : calc_distance ( row ), axis = 1 ) return df city_sub ( row ) Idenifies whether a city subsitution can be used. This function handles cases where the Incident City is null and it looks for a city in Residence City. If there is one, it subsitutes the latter for the former. Parameters: Name Type Description Default row Series row in a dataframe required Returns: Type Description tuple tuple[str, bool]: a tuple containing the city and whether it was subsituted Source code in geocoding/case_archive_utils.py def city_sub ( row : pd . Series ) -> tuple [ str , bool ]: \"\"\"Idenifies whether a city subsitution can be used. This function handles cases where the Incident City is null and it looks for a city in Residence City. If there is one, it subsitutes the latter for the former. Args: row (pd.Series): row in a dataframe Returns: tuple[str, bool]: a tuple containing the city and whether it was subsituted \"\"\" if pd . notna ( row [ \"Incident City\" ]): city = row [ \"Incident City\" ] . title () . strip () subbed = False elif pd . isna ( row [ \"Incident City\" ]) and pd . notna ( row [ \"Residence City\" ]): city = row [ \"Residence City\" ] . title () . strip () subbed = True else : city = \"\" subbed = False return city , subbed clean_address ( row ) Cleans an address by calling other utility functions. Parameters: Name Type Description Default row Series row in a dataframe required Returns: Type Description Union[int, str] Union[int, str, None]: cleaned address or None Source code in geocoding/case_archive_utils.py def clean_address ( row : pd . Series ) -> Union [ int , str , None ]: \"\"\"Cleans an address by calling other utility functions. Args: row (pd.Series): row in a dataframe Returns: Union[int, str, None]: cleaned address or None \"\"\" a = row [ \"Incident Address\" ] # handles 'unknown' and variations if \"unk\" in a . lower (): return None no_apartment_info = remove_apartment_info ( a . lower ()) no_commas = deal_with_commas ( no_apartment_info ) return no_commas create_address ( row ) Creates the address field column for each row of a dataframe. Calls city_sub. Parameters: Name Type Description Default row Series row in a dataframe. required Returns: Type Description tuple tuple[str, bool]: cleaned address and whether a city substitution was performed. Source code in geocoding/case_archive_utils.py def create_address ( row : pd . Series ) -> tuple [ str , bool ]: \"\"\"Creates the address field column for each row of a dataframe. Calls city_sub. Args: row (pd.Series): row in a dataframe. Returns: tuple[str, bool]: cleaned address and whether a city substitution was performed. \"\"\" street = row [ \"clean_address\" ] city , city_subbed = city_sub ( row ) zip_code = ( \"\" if pd . isna ( row [ \"Incident Zip Code\" ]) else row [ \"Incident Zip Code\" ] . strip () ) address = f \" { street } { city } { zip_code } \" return address . strip (), city_subbed deal_with_commas ( x ) Handles commas and stripping and title-casing in Address field. Parameters: Name Type Description Default x str Address required Returns: Type Description str str: Cleaned address Source code in geocoding/case_archive_utils.py def deal_with_commas ( x : str ) -> str : \"\"\"Handles commas and stripping and title-casing in Address field. Args: x (str): Address Returns: str: Cleaned address \"\"\" if \",\" not in x : return x . strip () . title () # TODO: debug # ! what is this second section of code doing? parts = x . split ( \",\" ) result = \" \" . join ([ z for z in parts if any ( y for y in z if y . isnumeric ())]) return result . strip () . title () dump_case_archive_data ( df ) Dumps the provided dataframe to file. Source code in geocoding/case_archive_utils.py def dump_case_archive_data ( df : pd . DataFrame ): \"\"\"Dumps the provided dataframe to file.\"\"\" df . to_csv ( \"./data/geocoded_case_archives.csv\" , index = False ) geocode_case_archive ( df ) Geocodes each row in the case archives dataframe. This function takes the full address column and geocodes it. The resulting dataframe has three new columns: coded_lat, coded_long, and coded_score. Parameters: Name Type Description Default df DataFrame case archives dataframe. required Returns: Type Description DataFrame pd.DataFrame: geocoded dataframe. Source code in geocoding/case_archive_utils.py def geocode_case_archive ( df : pd . DataFrame ) -> pd . DataFrame : \"\"\"Geocodes each row in the case archives dataframe. This function takes the full address column and geocodes it. The resulting dataframe has three new columns: coded_lat, coded_long, and coded_score. Args: df (pd.DataFrame): case archives dataframe. Returns: pd.DataFrame: geocoded dataframe. \"\"\" geolocator = ArcGIS () geocode = RateLimiter ( geolocator . geocode , min_delay_seconds = 0 ) df [ \"geo_location\" ] = df [ \"full_address\" ] . progress_apply ( geocode ) df [ \"coded_lat\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . latitude if pd . notna ( x ) else None ) df [ \"coded_long\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . longitude if pd . notna ( x ) else None ) df [ \"coded_score\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . raw . get ( \"score\" ) if pd . notna ( x ) else None ) df . drop ( \"geo_location\" , axis = 1 , inplace = True ) return df load_case_archive_data () Utility function to load in ME dataset from file. This function also removes records where the Incident Address is null and applies the clean address method. Source code in geocoding/case_archive_utils.py def load_case_archive_data () -> pd . DataFrame : \"\"\"Utility function to load in ME dataset from file. This function also removes records where the Incident Address is null and applies the clean address method. \"\"\" df = pd . read_csv ( \"./data/Medical_Examiner_Case_Archive.csv\" ) # drop where Incident Address is None df = df [ df [ \"Incident Address\" ] . notna ()] # regex removal df [ \"clean_address\" ] = df . apply ( lambda row : clean_address ( row ), axis = 1 ) df = df [ df [ \"clean_address\" ] . notna ()] # subs city if needed and combines address fields addresses = df . apply ( lambda row : create_address ( row ), axis = 1 ) df [ \"full_address\" ] = [ a [ 0 ] for a in addresses ] df [ \"city_subbed\" ] = [ a [ 1 ] for a in addresses ] return df remove_apartment_info ( x ) Uses regex to remove # and Apt from Address Parameters: Name Type Description Default x str Address required Returns: Type Description str str: Cleaned address Source code in geocoding/case_archive_utils.py def remove_apartment_info ( x : str ) -> str : \"\"\"Uses regex to remove # and Apt from Address Args: x (str): Address Returns: str: Cleaned address \"\"\" # regex 1 to look for apartments and #s result1 = re . sub ( r \"apt.*|\\#.*|.*nh,\" , \"\" , x ) # regex 2 to specify only alphanumeric + '.' for abbreviations and spaces result2 = re . sub ( r \"[^a-zA-Z0-9.\\s]\" , \"\" , result1 ) return result2 rendering: show_source: true show_root_heading: false","title":"Case Archive Utils"},{"location":"api-reference/case-archive-utils/#case-archive-utils","text":"","title":"Case Archive Utils"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.calculate_distance","text":"Calculates distance from original lat/long to geocoded lat/long. Parameters: Name Type Description Default df DataFrame original df required Returns: Type Description DataFrame pd.DataFrame: dataframe with distance column Source code in geocoding/case_archive_utils.py def calculate_distance ( df : pd . DataFrame ) -> pd . DataFrame : \"\"\"Calculates distance from original lat/long to geocoded lat/long. Args: df (pd.DataFrame): original df Returns: pd.DataFrame: dataframe with distance column \"\"\" def calc_distance ( row ) -> Union [ None , float ]: if ( pd . isna ( row . latitude ) or pd . isna ( row . longitude ) or pd . isna ( row . coded_lat ) or pd . isna ( row . coded_long ) ): return None # distance in miles d = distance . distance ( ( row . latitude , row . longitude ), ( row . coded_lat , row . coded_long ) ) . mi return d df [ \"distance\" ] = df . apply ( lambda row : calc_distance ( row ), axis = 1 ) return df","title":"calculate_distance()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.city_sub","text":"Idenifies whether a city subsitution can be used. This function handles cases where the Incident City is null and it looks for a city in Residence City. If there is one, it subsitutes the latter for the former. Parameters: Name Type Description Default row Series row in a dataframe required Returns: Type Description tuple tuple[str, bool]: a tuple containing the city and whether it was subsituted Source code in geocoding/case_archive_utils.py def city_sub ( row : pd . Series ) -> tuple [ str , bool ]: \"\"\"Idenifies whether a city subsitution can be used. This function handles cases where the Incident City is null and it looks for a city in Residence City. If there is one, it subsitutes the latter for the former. Args: row (pd.Series): row in a dataframe Returns: tuple[str, bool]: a tuple containing the city and whether it was subsituted \"\"\" if pd . notna ( row [ \"Incident City\" ]): city = row [ \"Incident City\" ] . title () . strip () subbed = False elif pd . isna ( row [ \"Incident City\" ]) and pd . notna ( row [ \"Residence City\" ]): city = row [ \"Residence City\" ] . title () . strip () subbed = True else : city = \"\" subbed = False return city , subbed","title":"city_sub()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.clean_address","text":"Cleans an address by calling other utility functions. Parameters: Name Type Description Default row Series row in a dataframe required Returns: Type Description Union[int, str] Union[int, str, None]: cleaned address or None Source code in geocoding/case_archive_utils.py def clean_address ( row : pd . Series ) -> Union [ int , str , None ]: \"\"\"Cleans an address by calling other utility functions. Args: row (pd.Series): row in a dataframe Returns: Union[int, str, None]: cleaned address or None \"\"\" a = row [ \"Incident Address\" ] # handles 'unknown' and variations if \"unk\" in a . lower (): return None no_apartment_info = remove_apartment_info ( a . lower ()) no_commas = deal_with_commas ( no_apartment_info ) return no_commas","title":"clean_address()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.create_address","text":"Creates the address field column for each row of a dataframe. Calls city_sub. Parameters: Name Type Description Default row Series row in a dataframe. required Returns: Type Description tuple tuple[str, bool]: cleaned address and whether a city substitution was performed. Source code in geocoding/case_archive_utils.py def create_address ( row : pd . Series ) -> tuple [ str , bool ]: \"\"\"Creates the address field column for each row of a dataframe. Calls city_sub. Args: row (pd.Series): row in a dataframe. Returns: tuple[str, bool]: cleaned address and whether a city substitution was performed. \"\"\" street = row [ \"clean_address\" ] city , city_subbed = city_sub ( row ) zip_code = ( \"\" if pd . isna ( row [ \"Incident Zip Code\" ]) else row [ \"Incident Zip Code\" ] . strip () ) address = f \" { street } { city } { zip_code } \" return address . strip (), city_subbed","title":"create_address()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.deal_with_commas","text":"Handles commas and stripping and title-casing in Address field. Parameters: Name Type Description Default x str Address required Returns: Type Description str str: Cleaned address Source code in geocoding/case_archive_utils.py def deal_with_commas ( x : str ) -> str : \"\"\"Handles commas and stripping and title-casing in Address field. Args: x (str): Address Returns: str: Cleaned address \"\"\" if \",\" not in x : return x . strip () . title () # TODO: debug # ! what is this second section of code doing? parts = x . split ( \",\" ) result = \" \" . join ([ z for z in parts if any ( y for y in z if y . isnumeric ())]) return result . strip () . title ()","title":"deal_with_commas()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.dump_case_archive_data","text":"Dumps the provided dataframe to file. Source code in geocoding/case_archive_utils.py def dump_case_archive_data ( df : pd . DataFrame ): \"\"\"Dumps the provided dataframe to file.\"\"\" df . to_csv ( \"./data/geocoded_case_archives.csv\" , index = False )","title":"dump_case_archive_data()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.geocode_case_archive","text":"Geocodes each row in the case archives dataframe. This function takes the full address column and geocodes it. The resulting dataframe has three new columns: coded_lat, coded_long, and coded_score. Parameters: Name Type Description Default df DataFrame case archives dataframe. required Returns: Type Description DataFrame pd.DataFrame: geocoded dataframe. Source code in geocoding/case_archive_utils.py def geocode_case_archive ( df : pd . DataFrame ) -> pd . DataFrame : \"\"\"Geocodes each row in the case archives dataframe. This function takes the full address column and geocodes it. The resulting dataframe has three new columns: coded_lat, coded_long, and coded_score. Args: df (pd.DataFrame): case archives dataframe. Returns: pd.DataFrame: geocoded dataframe. \"\"\" geolocator = ArcGIS () geocode = RateLimiter ( geolocator . geocode , min_delay_seconds = 0 ) df [ \"geo_location\" ] = df [ \"full_address\" ] . progress_apply ( geocode ) df [ \"coded_lat\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . latitude if pd . notna ( x ) else None ) df [ \"coded_long\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . longitude if pd . notna ( x ) else None ) df [ \"coded_score\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . raw . get ( \"score\" ) if pd . notna ( x ) else None ) df . drop ( \"geo_location\" , axis = 1 , inplace = True ) return df","title":"geocode_case_archive()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.load_case_archive_data","text":"Utility function to load in ME dataset from file. This function also removes records where the Incident Address is null and applies the clean address method. Source code in geocoding/case_archive_utils.py def load_case_archive_data () -> pd . DataFrame : \"\"\"Utility function to load in ME dataset from file. This function also removes records where the Incident Address is null and applies the clean address method. \"\"\" df = pd . read_csv ( \"./data/Medical_Examiner_Case_Archive.csv\" ) # drop where Incident Address is None df = df [ df [ \"Incident Address\" ] . notna ()] # regex removal df [ \"clean_address\" ] = df . apply ( lambda row : clean_address ( row ), axis = 1 ) df = df [ df [ \"clean_address\" ] . notna ()] # subs city if needed and combines address fields addresses = df . apply ( lambda row : create_address ( row ), axis = 1 ) df [ \"full_address\" ] = [ a [ 0 ] for a in addresses ] df [ \"city_subbed\" ] = [ a [ 1 ] for a in addresses ] return df","title":"load_case_archive_data()"},{"location":"api-reference/case-archive-utils/#src.geocoding.case_archive_utils.remove_apartment_info","text":"Uses regex to remove # and Apt from Address Parameters: Name Type Description Default x str Address required Returns: Type Description str str: Cleaned address Source code in geocoding/case_archive_utils.py def remove_apartment_info ( x : str ) -> str : \"\"\"Uses regex to remove # and Apt from Address Args: x (str): Address Returns: str: Cleaned address \"\"\" # regex 1 to look for apartments and #s result1 = re . sub ( r \"apt.*|\\#.*|.*nh,\" , \"\" , x ) # regex 2 to specify only alphanumeric + '.' for abbreviations and spaces result2 = re . sub ( r \"[^a-zA-Z0-9.\\s]\" , \"\" , result1 ) return result2 rendering: show_source: true show_root_heading: false","title":"remove_apartment_info()"},{"location":"api-reference/distance-utils/","text":"Distance Utils apply_distance () Utility function to apply the distance calculation and save the resulting file. Source code in geocoding/distance_utils.py def apply_distance (): \"\"\"Utility function to apply the distance calculation and save the resulting file.\"\"\" case_archives = pd . read_csv ( \"./data/geocoded_case_archives.csv\" , low_memory = False ) pharm_point_list = get_pharmacy_points () case_archives [ \"nearest_pharmacy\" ] = case_archives . progress_apply ( lambda row : calculate_distance ( row , pharm_point_list ), axis = 1 ) case_archives . to_csv ( \"./data/case_archives_distances.csv\" , index = False ) calculate_distance ( row , pharm_points ) Calculates the minimum distance between each row and the points. This function calculates the distance from the row's lat/long to all of the pharm_points in miles and then returns the minimum distance for each row. Parameters: Name Type Description Default row Series row of the dataframe required pharm_points list list of lat/long points required Returns: Type Description Optional[float] Union[float, None]: Distance in miles or None if no lat/long provided in the row. Source code in geocoding/distance_utils.py def calculate_distance ( row : pd . Series , pharm_points : list [ tuple [ float , float ]] ) -> Union [ float , None ]: \"\"\"Calculates the minimum distance between each row and the points. This function calculates the distance from the row's lat/long to all of the pharm_points in miles and then returns the minimum distance for each row. Args: row (pd.Series): row of the dataframe pharm_points (list[tuple[float, float]]): list of lat/long points Returns: Union[float, None]: Distance in miles or None if no lat/long provided in the row. \"\"\" distances = [] if pd . isna ( row . coded_lat ) or pd . isna ( row . coded_long ): return None for p in pharm_points : d = distance . distance ( ( row . coded_lat , row . coded_long ), # case archive (point1) ( p [ 0 ], p [ 1 ]), # pharmacy (point2) ) # miles distances . append ( d . mi ) return min ( distances ) get_pharmacy_points () Gets lat/long points from geocoded pharmacy file. Returns: Type Description list list[tuple[float, float]]: list of (lat, long) Source code in geocoding/distance_utils.py def get_pharmacy_points () -> list [ tuple [ float , float ]]: \"\"\"Gets lat/long points from geocoded pharmacy file. Returns: list[tuple[float, float]]: list of (lat, long) \"\"\" points = [] pharmacies = pd . read_csv ( \"./data/geocoded_pharmacies.csv\" ) for _ , pharm in pharmacies . iterrows (): if pd . notna ( pharm . coded_lat ) and pd . notna ( pharm . coded_long ): point = ( pharm . coded_lat , pharm . coded_long ) points . append ( point ) return points rendering: show_source: true show_root_heading: false","title":"Distance Utils"},{"location":"api-reference/distance-utils/#distance-utils","text":"","title":"Distance Utils"},{"location":"api-reference/distance-utils/#src.geocoding.distance_utils.apply_distance","text":"Utility function to apply the distance calculation and save the resulting file. Source code in geocoding/distance_utils.py def apply_distance (): \"\"\"Utility function to apply the distance calculation and save the resulting file.\"\"\" case_archives = pd . read_csv ( \"./data/geocoded_case_archives.csv\" , low_memory = False ) pharm_point_list = get_pharmacy_points () case_archives [ \"nearest_pharmacy\" ] = case_archives . progress_apply ( lambda row : calculate_distance ( row , pharm_point_list ), axis = 1 ) case_archives . to_csv ( \"./data/case_archives_distances.csv\" , index = False )","title":"apply_distance()"},{"location":"api-reference/distance-utils/#src.geocoding.distance_utils.calculate_distance","text":"Calculates the minimum distance between each row and the points. This function calculates the distance from the row's lat/long to all of the pharm_points in miles and then returns the minimum distance for each row. Parameters: Name Type Description Default row Series row of the dataframe required pharm_points list list of lat/long points required Returns: Type Description Optional[float] Union[float, None]: Distance in miles or None if no lat/long provided in the row. Source code in geocoding/distance_utils.py def calculate_distance ( row : pd . Series , pharm_points : list [ tuple [ float , float ]] ) -> Union [ float , None ]: \"\"\"Calculates the minimum distance between each row and the points. This function calculates the distance from the row's lat/long to all of the pharm_points in miles and then returns the minimum distance for each row. Args: row (pd.Series): row of the dataframe pharm_points (list[tuple[float, float]]): list of lat/long points Returns: Union[float, None]: Distance in miles or None if no lat/long provided in the row. \"\"\" distances = [] if pd . isna ( row . coded_lat ) or pd . isna ( row . coded_long ): return None for p in pharm_points : d = distance . distance ( ( row . coded_lat , row . coded_long ), # case archive (point1) ( p [ 0 ], p [ 1 ]), # pharmacy (point2) ) # miles distances . append ( d . mi ) return min ( distances )","title":"calculate_distance()"},{"location":"api-reference/distance-utils/#src.geocoding.distance_utils.get_pharmacy_points","text":"Gets lat/long points from geocoded pharmacy file. Returns: Type Description list list[tuple[float, float]]: list of (lat, long) Source code in geocoding/distance_utils.py def get_pharmacy_points () -> list [ tuple [ float , float ]]: \"\"\"Gets lat/long points from geocoded pharmacy file. Returns: list[tuple[float, float]]: list of (lat, long) \"\"\" points = [] pharmacies = pd . read_csv ( \"./data/geocoded_pharmacies.csv\" ) for _ , pharm in pharmacies . iterrows (): if pd . notna ( pharm . coded_lat ) and pd . notna ( pharm . coded_long ): point = ( pharm . coded_lat , pharm . coded_long ) points . append ( point ) return points rendering: show_source: true show_root_heading: false","title":"get_pharmacy_points()"},{"location":"api-reference/pharmacy-utils/","text":"Pharmacy Utils dump_pharmacy_data ( df ) Utility function to dump geocoded dataframe to file. Source code in geocoding/pharmacy_utils.py def dump_pharmacy_data ( df : pd . DataFrame ): \"\"\"Utility function to dump geocoded dataframe to file.\"\"\" df . to_csv ( \"./data/geocoded_pharmacies.csv\" , index = False ) geocode_pharmacy ( df ) Geocodes the pharmacies. Gets latitude, longitude, and accuracy score for each pharmacy. Parameters: Name Type Description Default df DataFrame Pharmacy dataframe required Returns: Type Description DataFrame pd.DataFrame: Geocoded pharmacy dataframe. Source code in geocoding/pharmacy_utils.py def geocode_pharmacy ( df : pd . DataFrame ) -> pd . DataFrame : \"\"\"Geocodes the pharmacies. Gets latitude, longitude, and accuracy score for each pharmacy. Args: df (pd.DataFrame): Pharmacy dataframe Returns: pd.DataFrame: Geocoded pharmacy dataframe. \"\"\" geolocator = ArcGIS () geocode = RateLimiter ( geolocator . geocode ) # default to 0.0 delay df [ \"geo_location\" ] = df [ \"full_address\" ] . progress_apply ( geocode ) df [ \"coded_lat\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . latitude ) df [ \"coded_long\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . longitude ) df [ \"coded_score\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . raw . get ( \"score\" )) df . drop ( \"geo_location\" , axis = 1 , inplace = True ) return df load_pharmacy_data () Loads pharmacy datafile. Also makes 'full_address' column. Returns: Type Description DataFrame pd.DataFrame: Loaded dataframe. Source code in geocoding/pharmacy_utils.py def load_pharmacy_data () -> pd . DataFrame : \"\"\"Loads pharmacy datafile. Also makes 'full_address' column. Returns: pd.DataFrame: Loaded dataframe. \"\"\" df = pd . read_csv ( \"./data/CookCounty_Pharmacies.csv\" ) df [ \"full_address\" ] = df . apply ( lambda row : make_pharmacy_address ( row ), axis = 1 ) return df make_pharmacy_address ( row ) Utility function to combine fields into one address field. The row for this function should have PharmacyAddress, City, State, and Zip fields. Parameters: Name Type Description Default row Series Row in a dataframe required Returns: Type Description str str: Concatenated string for full address Source code in geocoding/pharmacy_utils.py def make_pharmacy_address ( row : pd . Series ) -> str : \"\"\"Utility function to combine fields into one address field. The row for this function should have PharmacyAddress, City, State, and Zip fields. Args: row (pd.Series): Row in a dataframe Returns: str: Concatenated string for full address \"\"\" street = row [ \"PharmacyAddress\" ] city = row [ \"City\" ] state = row [ \"State\" ] zip_code = row [ \"Zip\" ] address = f \" { street } { city } { state } { zip_code } \" . strip () return address rendering: show_source: true show_root_heading: false","title":"Pharmacy Utils"},{"location":"api-reference/pharmacy-utils/#pharmacy-utils","text":"","title":"Pharmacy Utils"},{"location":"api-reference/pharmacy-utils/#src.geocoding.pharmacy_utils.dump_pharmacy_data","text":"Utility function to dump geocoded dataframe to file. Source code in geocoding/pharmacy_utils.py def dump_pharmacy_data ( df : pd . DataFrame ): \"\"\"Utility function to dump geocoded dataframe to file.\"\"\" df . to_csv ( \"./data/geocoded_pharmacies.csv\" , index = False )","title":"dump_pharmacy_data()"},{"location":"api-reference/pharmacy-utils/#src.geocoding.pharmacy_utils.geocode_pharmacy","text":"Geocodes the pharmacies. Gets latitude, longitude, and accuracy score for each pharmacy. Parameters: Name Type Description Default df DataFrame Pharmacy dataframe required Returns: Type Description DataFrame pd.DataFrame: Geocoded pharmacy dataframe. Source code in geocoding/pharmacy_utils.py def geocode_pharmacy ( df : pd . DataFrame ) -> pd . DataFrame : \"\"\"Geocodes the pharmacies. Gets latitude, longitude, and accuracy score for each pharmacy. Args: df (pd.DataFrame): Pharmacy dataframe Returns: pd.DataFrame: Geocoded pharmacy dataframe. \"\"\" geolocator = ArcGIS () geocode = RateLimiter ( geolocator . geocode ) # default to 0.0 delay df [ \"geo_location\" ] = df [ \"full_address\" ] . progress_apply ( geocode ) df [ \"coded_lat\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . latitude ) df [ \"coded_long\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . longitude ) df [ \"coded_score\" ] = df [ \"geo_location\" ] . apply ( lambda x : x . raw . get ( \"score\" )) df . drop ( \"geo_location\" , axis = 1 , inplace = True ) return df","title":"geocode_pharmacy()"},{"location":"api-reference/pharmacy-utils/#src.geocoding.pharmacy_utils.load_pharmacy_data","text":"Loads pharmacy datafile. Also makes 'full_address' column. Returns: Type Description DataFrame pd.DataFrame: Loaded dataframe. Source code in geocoding/pharmacy_utils.py def load_pharmacy_data () -> pd . DataFrame : \"\"\"Loads pharmacy datafile. Also makes 'full_address' column. Returns: pd.DataFrame: Loaded dataframe. \"\"\" df = pd . read_csv ( \"./data/CookCounty_Pharmacies.csv\" ) df [ \"full_address\" ] = df . apply ( lambda row : make_pharmacy_address ( row ), axis = 1 ) return df","title":"load_pharmacy_data()"},{"location":"api-reference/pharmacy-utils/#src.geocoding.pharmacy_utils.make_pharmacy_address","text":"Utility function to combine fields into one address field. The row for this function should have PharmacyAddress, City, State, and Zip fields. Parameters: Name Type Description Default row Series Row in a dataframe required Returns: Type Description str str: Concatenated string for full address Source code in geocoding/pharmacy_utils.py def make_pharmacy_address ( row : pd . Series ) -> str : \"\"\"Utility function to combine fields into one address field. The row for this function should have PharmacyAddress, City, State, and Zip fields. Args: row (pd.Series): Row in a dataframe Returns: str: Concatenated string for full address \"\"\" street = row [ \"PharmacyAddress\" ] city = row [ \"City\" ] state = row [ \"State\" ] zip_code = row [ \"Zip\" ] address = f \" { street } { city } { state } { zip_code } \" . strip () return address rendering: show_source: true show_root_heading: false","title":"make_pharmacy_address()"},{"location":"api-reference/spatial-join/","text":"Spatial Join load_files () Utility function to load both data files. Returns: Type Description dict pd.DataFrame containing geocoded_case_archives and gpd.GeoDataFrame containing land_use polygons Source code in geocoding/spatial_join.py def load_files () -> dict [ str , typing . Union [ pd . DataFrame , gpd . GeoDataFrame ]]: \"\"\"Utility function to load both data files. Returns: pd.DataFrame containing geocoded_case_archives and gpd.GeoDataFrame containing land_use polygons \"\"\" df = pd . read_csv ( \"./data/case_archives_distances.csv\" , low_memory = False ) land_use_map = gpd . read_file ( \"./data/LANDUSE_SHAPES/land_use.shp\" ) land_use_map . drop ( [ \"FIRST_COUN\" , \"LANDUSE\" , \"LANDUSE2\" , \"OS_MGMT\" , \"FAC_NAME\" , \"PLATTED\" , \"MODIFIER\" , \"Shape_Leng\" , \"Shape_Area\" , ], axis = 1 , inplace = True , ) return { \"case_archives\" : df , \"land_use\" : land_use_map } make_point_geometries ( dataframe ) [summary] Parameters: Name Type Description Default dataframe DataFrame [description] required Returns: Type Description GeoDataFrame gpd.GeoDataFrame: [description] Source code in geocoding/spatial_join.py def make_point_geometries ( dataframe : pd . DataFrame ) -> gpd . GeoDataFrame : \"\"\"[summary] Args: dataframe (pd.DataFrame): [description] Returns: gpd.GeoDataFrame: [description] \"\"\" df = dataframe [ dataframe . coded_lat . notna ()] geo_df = gpd . GeoDataFrame ( df , geometry = gpd . points_from_xy ( df . coded_long , df . coded_lat ), crs = \"EPSG:4326\" ) return geo_df spatially_join ( point_df , polygon_df ) [summary] Parameters: Name Type Description Default point_df GeoDataFrame [description] required polygon_df GeoDataFrame [description] required Returns: Type Description GeoDataFrame gpd.GeoDataFrame: [description] Source code in geocoding/spatial_join.py def spatially_join ( point_df : gpd . GeoDataFrame , polygon_df : gpd . GeoDataFrame ) -> gpd . GeoDataFrame : \"\"\"[summary] Args: point_df (gpd.GeoDataFrame): [description] polygon_df (gpd.GeoDataFrame): [description] Returns: gpd.GeoDataFrame: [description] \"\"\" geo_points = point_df . to_crs ( polygon_df . crs ) merged_data = gpd . sjoin ( geo_points , polygon_df , how = \"left\" ) return merged_data write_joined_file ( geo_dataframe ) Utility function to write geodataframe to file. Source code in geocoding/spatial_join.py def write_joined_file ( geo_dataframe : gpd . GeoDataFrame ): \"\"\"Utility function to write geodataframe to file.\"\"\" geo_dataframe . to_csv ( \"./data/joined_records.csv\" , index = False ) rendering: show_source: true show_root_heading: false","title":"Spatial Join"},{"location":"api-reference/spatial-join/#spatial-join","text":"","title":"Spatial Join"},{"location":"api-reference/spatial-join/#src.geocoding.spatial_join.load_files","text":"Utility function to load both data files. Returns: Type Description dict pd.DataFrame containing geocoded_case_archives and gpd.GeoDataFrame containing land_use polygons Source code in geocoding/spatial_join.py def load_files () -> dict [ str , typing . Union [ pd . DataFrame , gpd . GeoDataFrame ]]: \"\"\"Utility function to load both data files. Returns: pd.DataFrame containing geocoded_case_archives and gpd.GeoDataFrame containing land_use polygons \"\"\" df = pd . read_csv ( \"./data/case_archives_distances.csv\" , low_memory = False ) land_use_map = gpd . read_file ( \"./data/LANDUSE_SHAPES/land_use.shp\" ) land_use_map . drop ( [ \"FIRST_COUN\" , \"LANDUSE\" , \"LANDUSE2\" , \"OS_MGMT\" , \"FAC_NAME\" , \"PLATTED\" , \"MODIFIER\" , \"Shape_Leng\" , \"Shape_Area\" , ], axis = 1 , inplace = True , ) return { \"case_archives\" : df , \"land_use\" : land_use_map }","title":"load_files()"},{"location":"api-reference/spatial-join/#src.geocoding.spatial_join.make_point_geometries","text":"[summary] Parameters: Name Type Description Default dataframe DataFrame [description] required Returns: Type Description GeoDataFrame gpd.GeoDataFrame: [description] Source code in geocoding/spatial_join.py def make_point_geometries ( dataframe : pd . DataFrame ) -> gpd . GeoDataFrame : \"\"\"[summary] Args: dataframe (pd.DataFrame): [description] Returns: gpd.GeoDataFrame: [description] \"\"\" df = dataframe [ dataframe . coded_lat . notna ()] geo_df = gpd . GeoDataFrame ( df , geometry = gpd . points_from_xy ( df . coded_long , df . coded_lat ), crs = \"EPSG:4326\" ) return geo_df","title":"make_point_geometries()"},{"location":"api-reference/spatial-join/#src.geocoding.spatial_join.spatially_join","text":"[summary] Parameters: Name Type Description Default point_df GeoDataFrame [description] required polygon_df GeoDataFrame [description] required Returns: Type Description GeoDataFrame gpd.GeoDataFrame: [description] Source code in geocoding/spatial_join.py def spatially_join ( point_df : gpd . GeoDataFrame , polygon_df : gpd . GeoDataFrame ) -> gpd . GeoDataFrame : \"\"\"[summary] Args: point_df (gpd.GeoDataFrame): [description] polygon_df (gpd.GeoDataFrame): [description] Returns: gpd.GeoDataFrame: [description] \"\"\" geo_points = point_df . to_crs ( polygon_df . crs ) merged_data = gpd . sjoin ( geo_points , polygon_df , how = \"left\" ) return merged_data","title":"spatially_join()"},{"location":"api-reference/spatial-join/#src.geocoding.spatial_join.write_joined_file","text":"Utility function to write geodataframe to file. Source code in geocoding/spatial_join.py def write_joined_file ( geo_dataframe : gpd . GeoDataFrame ): \"\"\"Utility function to write geodataframe to file.\"\"\" geo_dataframe . to_csv ( \"./data/joined_records.csv\" , index = False ) rendering: show_source: true show_root_heading: false","title":"write_joined_file()"}]}